csdn的文章当然可以直接收藏，但是其他的一些十分有帮助或是写的十分好的文章就没法收藏了，然后转载的话太麻烦了，感觉也没必要，所以单独开一个博文，记录一下写的非常好的文章，也是类似于收藏夹这样子。

## 机器学习/统计
[python计算spearman相关系数（同时进行显著性检验）](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.spearmanr.html)
**因子分析**
[python package factor-analyzer 0.3.2](https://factor-analyzer.readthedocs.io/en/latest/factor_analyzer.html)(网上有一些这个包的信息，但是可能是改版了吧，语句会报错，这个应该是这个包最新的信息了，这个相对于skilearn的factor analysis可以做因子旋转)
[factor analysis 教学，结合上一个链接中的官方信息，里面是较老版本的，有些代码要改改](https://www.datacamp.com/community/tutorials/introduction-factor-analysis)
[验证性因子分析介绍CFA](https://baijiahao.baidu.com/s?id=1639373931503335703&wfr=spider&for=pc)
[验证性因子分析实例介绍](https://www.jianshu.com/p/844f600f03c2)
（上面两篇都是SPSSAU出的，所以很偏应用，很容易理解，小白看看很好的）


[轮廓系数计算](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.silhouette_score.html)
[对一个turple组成的list进行排序（排序的key可以是turple中的一个元素）](https://www.runoob.com/python/python-func-sorted.html)
[SPSS做卡方检验详细介绍](https://wenku.baidu.com/view/6963c7d7195f312b3169a585.html)
[3种t检验介绍](https://baijiahao.baidu.com/s?id=1636037420591254317&wfr=spider&for=pc)
[医咖会SPSS教学（质量很高）](http://www.datasoldier.net/archives/588)
[医咖会官网](https://www.mediecogroup.com/)
[效度分析介绍](https://baijiahao.baidu.com/s?id=1634939545819066878&wfr=spider&for=pc)
**arima模型**
[python进行arima预测1](https://www.sohu.com/a/273034912_654419)
[python进行arima预测2](https://www.jb51.net/article/158932.htm)

[哑变量是什么以及何时需要哑变量](https://mp.weixin.qq.com/s?__biz=MzI2OTQyMzc5MA==&mid=2247488620&idx=1&sn=108dd7f160399b4946a064c82396ce6c&chksm=eae1d1addd9658bb5a8a4a7d769ee015e29c33e8594e770752b8c55a3f483a3702d693f441ea&scene=21#wechat_redirect)
[离群值、强杠杆点、强影响点](https://www.cnblogs.com/HuZihu/p/12017890.html)
[多元回归是否需要归一化操作](http://www.datasoldier.net/archives/929)
[稳健性检验](https://zhuanlan.zhihu.com/p/35518844)
**spss数据离散化**
[spss数据离散化具体操作方法](https://new.qq.com/omn/20180420/20180420G1YBQU.html)
[SPSS数据离散化介绍和最优离散化方法](http://www.17bigdata.com/spss%E5%B8%B8%E7%94%A8%E5%9F%BA%E7%A1%80%E6%93%8D%E4%BD%9C-%E8%BF%9E%E7%BB%AD%E5%8F%98%E9%87%8F%E7%A6%BB%E6%95%A3%E5%8C%96/)
**调节回归**
[SPSS带有调节变量的分层回归1](https://wenku.baidu.com/view/ef2bb60eb84ae45c3b358c98.html)
[SPSS带有调节变量的分层回归2](https://www.zybang.com/question/c4544809339106a3696f0faaa9f154e5.html)
[自己写的调节回归的博文](https://blog.csdn.net/qq_39805362/article/details/105617883)
[调节变量的解释](https://www.douban.com/group/topic/146070006/)
**GBDT**
[gbdt文章介绍1（粗略介绍，可以形成一个大致的概念，里面似乎有一些问题，我在下面评论了）](https://www.jianshu.com/p/6755107e816d)
[gbdt2（写的很好，看后基本可以理解gbdt了）](https://www.cnblogs.com/ModifyRong/p/7744987.html)
[gbdt算法详解，更深入一些，可惜有些地方排版似乎出现了一些问题，只需要看最后作者自己的体会那一部分（“二. 对于GBDT的一些理解”）就可以，前面的是copy第二篇博文的](https://www.cnblogs.com/bnuvincent/p/9693190.html)
**XGBOOST**
看了下面这篇XGBOOST的文章，基本有个大概的了解，感觉xgboost主要是在优化函数上和gbdt有些不同，做了些改进，然后用了并行化，其他基本是一模一样的。
[关于xgboost，讲得很不错。里面数学推导部分没完全看懂，头晕晕。](https://www.cnblogs.com/zongfa/p/9324684.html)
[xgboost实战，写的非常清晰易懂，代码写的也很好](https://blog.csdn.net/qq_24519677/article/details/81869196)
[xgboost实战（我感觉没上面那篇好，这篇不看也没事）](https://www.cnblogs.com/wj-1314/p/9402324.html)

[推荐系统概述](https://www.cnblogs.com/NeilZhang/p/9900537.html)
**特征选择**
[特征选择RFE方法](https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.RFE.html)
[特征选择Relief算法](https://blog.csdn.net/ferrarild/article/details/18792613)
博文里有些地方没写清楚这里补充下：下面图中的N是特征数目的意思，A是特征，W（A）也就是特征A的权重，diff(A,R,M)是样本R和M在特征A上的差值，所以该行公式的意思就是利用同类最近邻和不同类最近邻样本来更新权重，同类最近邻样本比不同类最近邻样本近的话，权重增加，否则减小。
![在这里插入图片描述](https://img-blog.csdnimg.cn/2020042314534459.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM5ODA1MzYy,size_16,color_FFFFFF,t_70)
**正交实验设计**
[简单接触正交实验设计](http://www.datasoldier.net/archives/494)
[很好地介绍了正交实验设计](https://wenku.baidu.com/view/9fe8eaf49ec3d5bbfc0a741a.html)
[如何理解空白列](https://blog.tangxiaozhu.com/15270770828099.html)
[spss做正交实验方差分析](http://blog.sina.com.cn/s/blog_e86624500102v3ks.html)
[一篇写的不错的介绍文章](https://wenku.baidu.com/view/684ef3387f21af45b307e87101f69e314332fa0b.html)
[我对空白列的理解](https://blog.csdn.net/qq_39805362/article/details/105797704)

[sklearn交叉验证各种方法讲得很清晰](https://www.cnblogs.com/jiaxin359/p/8552800.html)
[网格搜索法进行参数选择](https://www.cnblogs.com/volcao/p/9086908.html)
[PCA做人脸识别讲得很清楚](https://blog.csdn.net/smartempire/article/details/21406005)
[计算距离矩阵](https://www.cnblogs.com/wuliytTaotao/p/12024380.html)
[决策树随机森林等模型的特征重要性绘图](https://www.jianshu.com/p/1900b7f58705)
[调查问卷和量表的区别及常用的分析方法](https://www.sohu.com/a/130160352_312708)
[SEM结构方程介绍](https://wenku.baidu.com/view/5272740df02d2af90242a8956bec0975f465a4c1.html)

**广义估计方程**
[广义估计方程spss](https://mp.weixin.qq.com/s?__biz=MzIzNjk2NDg4NA==&mid=2247484478&idx=1&sn=f8512bae38739c35b926b9f71e45f309&chksm=e8ce9945dfb91053646552c5498f971568e900d76d9506c9367e6ebc21af3af5f63eb5a2365c&token=1561722303&lang=zh_CN#rd)
[医咖会的广义估计方程spss教学](https://www.mediecogroup.com/method_article_detail/38/)

总体均值的置信区间等于样本均值加减估计误差，其中的估计误差等于所要求置信水平的临界值乘以样本均值的抽样标准差。
[样本均值的抽样标准差](https://zhidao.baidu.com/question/156864981.html)

**工具变量及两阶段最小二乘法的介绍**
顺序看下面三个链接可以了解工具变量和两阶段最小二乘法是什么，用来干什么。
[工具变量和两阶段回归法](https://wenku.baidu.com/view/22b3176114791711cd79171d.html)
[工具变量的解释](http://www.360doc.com/content/17/0801/09/39103730_675763624.shtml)
[二阶段最小二乘法的介绍](https://wenku.baidu.com/view/6abe384e0740be1e640e9a0e.html?rec_flag=default&sxts=1590286207609)

[线性回归和局部线性回归，讲得很不错](https://zhuanlan.zhihu.com/p/30422174)

**断点回归法介绍**
《基本无害的计量经济学》第三部分，有点点难
[断点回归法简单介绍，作为概述还可以](https://www.sohu.com/a/222098739_698752)
[这个也可一看](https://www.jianshu.com/p/c96cca68d518)
余静文 ,王春超 [J]新“拟随机实验”方法的兴起——断点回归及其在经济学中的应用.2011（对这两个方法的应用流程介绍的比较清晰了）
陈强老师的《高级计量经济学及Stata应用》（很清楚，而且看完就能用stata实操了）
**我整理的断点回归资料**
链接：https://pan.baidu.com/s/18Mm709wlAZgrN80ByllUjw 
提取码：m1l0


[二维正态分布通俗解释](https://wenku.baidu.com/view/37a4515f804d2b160b4ec088.html)
[多维正态分布](https://wenku.baidu.com/view/b74ec2bb5022aaea988f0f60.html)
[机器学习模型融合stacking1](https://zhuanlan.zhihu.com/p/26890738)
[机器学习模型融合stacking2](https://www.cnblogs.com/gczr/p/7144508.html)
[stacking讲解及实现代码](https://blog.csdn.net/jp_zhou256/article/details/83051796?utm_medium=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-1.nonecase&depth_1-utm_source=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-1.nonecase)

**典型相关分析**
[典型相关分析1](https://www.zhihu.com/question/52381656)
[典型相关分析2](https://blog.csdn.net/m0_37864814/article/details/89285240)
[典型相关分析3](https://wenku.baidu.com/view/ce9c0c93854769eae009581b6bd97f192279bfbe.html)
[spss操作 典型相关分析](https://blog.csdn.net/weixin_43756456/article/details/85625287)
![在这里插入图片描述](https://img-blog.csdnimg.cn/20200617132025778.png)
**PageRank**
[Pagerank讲解和代码（代码也不错可以直接用）](https://zhuanlan.zhihu.com/p/81691075)
[写的还不错的一个介绍](https://blog.csdn.net/weixin_43378396/article/details/90322422)
[大佬写的pagerank的介绍性文章](https://www.cnblogs.com/fengfenggirl/p/pagerank-introduction.html)
[大佬给的一个实例](https://www.cnblogs.com/fengfenggirl/p/pagerank-cnblogs.html)
[关于networkx实现pagerank的官方文档](https://networkx.github.io/documentation/networkx-1.10/reference/generated/networkx.algorithms.link_analysis.pagerank_alg.pagerank.html)
[networkx实现pagerank的一些说明](https://blog.csdn.net/a_31415926/article/details/40510175)
[我写的pagerank的代码](https://github.com/RobinYaoWenbin/Python-CommonCode/tree/master/python%E4%B8%9A%E5%8A%A1%E4%BB%A3%E7%A0%81/networkx-pagerank)

[各种信效度介绍](https://max.book118.com/html/2017/0905/132020415.shtm)
[各种信度介绍](https://baijiahao.baidu.com/s?id=1670811685756791784&wfr=spider&for=pc)
[Cronbach's α介绍](https://www.sohu.com/a/204514060_489312)

[stata面板数据处理的很好的教程](https://wenku.baidu.com/view/6cd81d7be518964bcf847c75.html)
[面板回归中的各种标准误](https://www.zhihu.com/question/23155918/answer/1132572042)

## 其他数据挖掘方法
[python实现TOPSIS方法](https://www.jianshu.com/p/85e63a5e063b)
[位图法](https://www.jianshu.com/p/f2257bfb77f5)（对于位图法我还希望进行一些补充说明：该文章中的N*sizeof(int)*8的sizeof实际上指的是一个int所需占用的Byte数目。位图法实际上就是新建一个array，然后这个array中的第几个数也就是第几个byte，然后这个数中的第几位为1就是所记录的数的位是多少。所以每一个数的存储实际上只需要一个bit。举个例子：一个int用32bit进行存储，然后我们new一个array[1000]，那么假如有一个数字5000，首先计算byte数5000/32=156，然后计算bit数5000%32=8，于是将array[156]的第8位从0变为1，就将5000这个数字存储好了。）

**层次分析法**
[层次分析法介绍，看完这个ppt就可以完全理解了](https://wenku.baidu.com/view/c9f29fc06f1aff00bed51ef9)
[一个层次分析法的计算案例以及大佬写的python代码](https://www.cnblogs.com/yhll/p/9967726.html)
[对第二个链接中的AHP的python代码做了一些注释](https://github.com/RobinYaoWenbin/Python-CommonCode/tree/master/python%E4%B8%9A%E5%8A%A1%E4%BB%A3%E7%A0%81/AHP%E5%B1%82%E6%AC%A1%E5%88%86%E6%9E%90%E6%B3%95)

**遗传算法**
[遗传算法的讲解](https://www.jianshu.com/p/ae5157c26af9)
[遗传算法的一个例子](https://www.cnblogs.com/chamie/p/4552066.html)

## 一些基本的计算机知识
[python3中encode、decode解读，各种编码方式说明](https://www.cnblogs.com/gengyufei/p/11344454.html)
[远程连接电脑](http://service.oray.com/question/1824.html)

## Linux
[centos7下安装mysql（成功）](https://www.cnblogs.com/nicknailo/articles/8563737.html)
[mysql在centos上进行配置](https://www.php.cn/mysql-tutorials-386847.html)
[删除不需要的RAID](http://blog.sina.com.cn/s/blog_53c984220102yaax.html)（首先用umount取消挂载后，fdisk -l查看依然存在磁盘阵列，然后vim /etc/fstab删除相关的RAID后，fdisk -l查看依然存在磁盘阵列，最后通过该文章里的方法终于成功删除掉了。）
[mysql重设密码（已成功）](https://www.cnblogs.com/gumuzi/p/5711495.html)
[linux下配置浙大vpn](https://github.com/QSCTech/zjunet/blob/master/README.zh.md)
[解决RHEL无法使用yum](https://blog.csdn.net/ming19951224/article/details/82874191)
[RHEL下安装Anaconda](https://www.cnblogs.com/dbf-/p/11031736.html)
[mysql报错“the table is full”](https://www.iteye.com/blog/zuzong-1071738)
[mysql报错“the table is full”2](https://stackoverflow.com/questions/21850287/error-1114-hy000-the-table-xxx-is-full)
[解决mysql root无法登录问题](https://blog.csdn.net/cll3830995/article/details/100297369)
[mysql数据库配置参数详解](https://www.jianshu.com/p/361f23277c41)

## 数据结构
[Trie树介绍](https://www.cnblogs.com/llllllpppppp/p/9449846.html)
## python
[地图可视化：folium](https://www.cnblogs.com/feffery/p/9282808.html)
[一个点位可视化的代码](https://github.com/RobinYaoWenbin/Python-CommonCode/tree/master/%E7%94%B5%E8%AD%A6%E7%82%B9%E4%BD%8D%E5%88%86%E5%B8%83folium)

## 其他
[可以直接访问的wiki 1](https://encyclopedia.thefreedictionary.com/factor+analysis)
[可以直接访问的wiki 2](https://en.jinzhao.wiki/wiki/K-means_clustering)
